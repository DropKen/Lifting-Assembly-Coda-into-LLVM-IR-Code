{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T11:11:11.941520Z",
     "start_time": "2025-10-23T11:11:11.935894Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Hello World!\")\n",
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T12:13:57.401138Z",
     "start_time": "2025-10-23T12:13:57.398138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"torch =\", torch.__version__)\n",
    "print(\"cuda_runtime =\", torch.version.cuda)\n",
    "print(\"cuda_available =\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"device =\", torch.cuda.get_device_name(0))\n"
   ],
   "id": "6351ccdc880cab3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch = 2.5.1+cu121\n",
      "cuda_runtime = 12.1\n",
      "cuda_available = True\n",
      "device = NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:53:50.018671Z",
     "start_time": "2025-10-23T14:53:49.253571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.backends.cudnn.version())\n",
    "#能够正确返回8200\n",
    "from torch.backends import cudnn # 若正常则静默\n",
    "cudnn.is_available()\n",
    "# 若正常返回True\n",
    "a=torch.tensor(1.)\n",
    "cudnn.is_acceptable(a.cuda())\n",
    "# 若正常返回True\n"
   ],
   "id": "ea6e3b2bb0356ecb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T13:00:52.492507Z",
     "start_time": "2025-10-23T13:00:45.721999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch, os\n",
    "model_dir = os.path.expanduser('models/Qwen2.5-Coder-3B-Instruct')\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
    "if tok.pad_token_id is None: tok.pad_token = tok.eos_token\n",
    "m = AutoModelForCausalLM.from_pretrained(model_dir, quantization_config=bnb, device_map=\"auto\")\n",
    "print(\"Loaded OK. dtype:\", next(m.parameters()).dtype)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device map keys:\", list(m.hf_device_map.keys())[:6], \"...\")"
   ],
   "id": "4f41073319e651d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OK. dtype: torch.float16\n",
      "CUDA available: True\n",
      "Device map keys: [''] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3d2415ad442b50d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
